{"nbformat":4,"nbformat_minor":5,"metadata":{"colab":{"name":"week12.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"contrary-capacity"},"source":["[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RikVoorhaar/optimization-II-2021/blob/master/notebooks/week12.ipynb)"],"id":"contrary-capacity"},{"cell_type":"markdown","metadata":{"id":"educated-dodge"},"source":["# Week 12"],"id":"educated-dodge"},{"cell_type":"markdown","metadata":{"id":"perceived-occasions"},"source":["## Exercise 1: Subgradients\n","\n","<div class=\"alert alert-info\">\n","Exercise\n","\n","Let $f\\colon \\Omega\\subset\\mathbb R^n\\to \\mathbb R$ (not necessarily convex or smooth). We call $g\\in \\mathbb R^n$ a _subgradient_ of $f$ at $x\\in\\Omega$ if:\n","$$\n","f(y)\\geq f(x)+g^\\top (y-x) \\qquad \\forall y\\in\\Omega\n","$$\n","\n","The set of all subgradients of $f$ at $x$ is denoted $\\partial f(x)$. Note that if $f$ is convex and differentiable at $x$ then $\\nabla f(x)\\in \\partial f(x)$, by the definition of a convex function. The point of subgradients is that they give a useful well-defined analogue of gradients at points where $f$ is _not_ differentiable.\n","\n","</div>"],"id":"perceived-occasions"},{"cell_type":"markdown","metadata":{"id":"UBs-TGlhn649"},"source":["### Exercise 1a) \n","<div class=\"alert alert-info\">\n","Exercise\n","\n","Show that $\\partial f(x)$ is a convex set.\n","\n","</div>"],"id":"UBs-TGlhn649"},{"cell_type":"markdown","metadata":{"id":"sNvOD-Ovn7A4"},"source":["### Exercise 1b)\n","<div class=\"alert alert-info\">\n","Exercise\n","\n","Let $f\\colon \\Omega\\subset\\mathbb R^n\\to \\mathbb R$. Let $x^*\\in \\Omega$. Show that $0\\in \\partial f(x^*)$ if and only if $x^*$ is a global minimizer. \n","\n","</div>"],"id":"sNvOD-Ovn7A4"},{"cell_type":"markdown","metadata":{"id":"hqbrX1FTn7EZ"},"source":["### Exercise 1c)\n","<div class=\"alert alert-info\">\n","Exercise\n","\n","Consider $f=|\\cdot|\\colon \\mathbb R\\to \\mathbb R$. Show that $\\partial f(0)=[-1,1]$ and conclude that $0$ is a global minimizer of $f$. \n","\n","</div>"],"id":"hqbrX1FTn7EZ"},{"cell_type":"markdown","metadata":{"id":"busvQLTw1Pyo"},"source":["### Exercise 1d)\n","<div class=\"alert alert-info\">\n","Exercise\n","\n","Let $f(x) = \\max_{i=1,\\dots,n} f_i(x)$. Show that \n","$$\n","\\partial f(x) \\supset \\text{Co}\\left(\\bigcup_{i\\mid f_i(x)=f(x)}\\partial f_i(x)\\right)\n","$$\n","\n","where Co denotes the convex hull. By $i\\mid f_i(x)=f(x)$ we mean those $i\\in\\{1,\\dots,m\\}$ such that $f_i(x)=f(x)$. \n","\n","_Remark: The opposite inclusion is also true, but a bit harder to show._\n","\n","</div>"],"id":"busvQLTw1Pyo"},{"cell_type":"markdown","metadata":{"id":"bLkr7wY5n7HM"},"source":["### Exercise 1e)\n","<div class=\"alert alert-info\">\n","Exercise\n","\n","Consider the function $f\\colon \\mathbb R^2\\to \\mathbb R$, $f(x,y)=\\max \\{f_1(x,y),\\,f_2(x,y)\\}$ with \n","$$\n","f_1(x,y) = x^2,\\qquad f_2(x,y) = \\alpha x^2+y\n","$$\n","\n","where $\\alpha\\in (0,1)$ is a fixed parameter. Compute $\\partial f(0,0)$ and show that $(0,0)$ is a global minimzer of $f$.\n","\n","_Hint: You can use the opposite inclusion of 1d):_ $\\partial f(x) = \\text{Co}\\left(\\bigcup_{i\\mid f_i(x)=f(x)}\\partial f_i(x)\\right)$\n","\n","\n","</div>"],"id":"bLkr7wY5n7HM"},{"cell_type":"markdown","metadata":{"id":"L4LfUNXLn7J_"},"source":["## Exercise 2: Gradient descent for quadratic problem\n","<div class=\"alert alert-info\">\n","Exercise\n","\n","Let $0\\prec A\\in \\mathbb R^{n\\times n}$ be a positive definite matrix, and let $b\\in\\mathbb R^n$ and $c\\in \\mathbb R$. We consider the problem of minimizing the quadratic function\n","$$\n","    f(x) = \\frac12x^\\top A x - b^\\top x+c\n","$$\n","\n","using gradient descent methods. Recall that this problem has unique minimizer $x_*=A^{-1}b$.\n","\n","</div>"],"id":"L4LfUNXLn7J_"},{"cell_type":"markdown","metadata":{"id":"xKpxCegOn7M0"},"source":["### Exercise 2a)\n","<div class=\"alert alert-info\">\n","Exercise\n","\n","Let $x_{k+1} = x_k-t\\nabla f(x_k)$. Show that \n","$$\n","    \\|x_{k+1}-x_*\\|\\leq \\|I-t A\\|\\|x_k-x_*\\|\n","$$\n","\n","where the norm on the left of the right-hand-side is [the operator norm.](https://en.wikipedia.org/wiki/Operator_norm)\n","\n","_Hint: You can use that_ $Ax_*=b$.\n","\n","</div>"],"id":"xKpxCegOn7M0"},{"cell_type":"markdown","metadata":{"id":"vTWelOxVEuD7"},"source":["### Exercise 2b)\n","<div class=\"alert alert-info\">\n","Exercise\n","\n","Let $\\lambda_1,\\lambda_n>0$ be respectively the smallest and biggest eigenvalue of $A$. Show that \n","$$\n","\\|I-tA\\| = \\max\\{|1-t\\lambda_1|,|1-t\\lambda_n|\\}$.\n","$$\n","\n","\n","_Hint: First show that_ $\\|I-tA\\| = \\max_i|1-t\\lambda_i|$ _with_ $\\lambda_i$ _the eigenvalues of_ $A$.\n","</div>"],"id":"vTWelOxVEuD7"},{"cell_type":"markdown","metadata":{"id":"ARlsWUe2EuG6"},"source":["### Exercise 2c)\n","<div class=\"alert alert-info\">\n","\n","\n","Show that $t=2/(\\lambda_1+\\lambda_n)$ minimizes $h(t)=\\|I-tA\\|$\n","\n","_Hint: You can use the fact that this function is minimized if and only if $0\\in\\partial h(t)$ (c.f. Exercise 1b) and 1d))_\n","\n","\n","\n","</div>"],"id":"ARlsWUe2EuG6"},{"cell_type":"markdown","metadata":{"id":"IT29dr6GEuJg"},"source":["### Exercise 2d)\n","<div class=\"alert alert-info\">\n","Exercise\n","\n","Using the previous exercises, derive a convergence rate $\\gamma>0$ of gradient descent with optimal step size $t$ in terms of the condition number $\\kappa = \\lambda_n/\\lambda_1$:\n","$$\n","    \\|x_k-x_*\\|\\leq \\gamma^k\\|x_0-x_*\\|\n","$$\n","\n","</div>"],"id":"IT29dr6GEuJg"}]}